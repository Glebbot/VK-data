{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "from LxmlSoup import LxmlSoup\n",
    "import nltk\n",
    "from time import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import DBSCAN, KMeans, SpectralClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from nltk.corpus import stopwords\n",
    "import pyprind\n",
    "import string\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Имя пользователя или название беседы\n",
    "NAME = None\n",
    "\n",
    "# Используемая модель (DBSCAN или KMeans)\n",
    "# При некорректном имени по умолчанию будет использован KMeans\n",
    "MODEL_TYPE = 'Spectral'\n",
    "\n",
    "# Максимальное количество кластеров (для KMeans и Spectral)\n",
    "MAX_CLUSTERS = 150\n",
    "\n",
    "# eta для DBSCAN\n",
    "ETA = 0.5\n",
    "\n",
    "# Использовать PCA перед кластеризацией (True или False)\n",
    "USE_PCA =False\n",
    "\n",
    "# Минимальный порог для TF-IDF\n",
    "MIN_DF = 5\n",
    "\n",
    "# Количество точек для визуализации PCA\n",
    "POINT_COUNT = 1000\n",
    "\n",
    "# Сохранять информацию в csv файле после парсинга (True или False)\n",
    "# Если False, при каждом новом запуске программы будет осуществляться повторный парсинг, что может занимать много времени\n",
    "SAVE_TO_CSV = True\n",
    "\n",
    "# Чтение информации из csv файла (True или False)\n",
    "# Если False, существующие csv файлы будут проигнорированы и перезаписаны (если SAVE_TO_CSV = True). Используйте если обновили данные архива\n",
    "READ_FROM_CSV = True\n",
    "\n",
    "# Количество компонент для PCA (график будет выведен только для 2 или 3 компонент)\n",
    "PCA_COMPONENTS = 3\n",
    "\n",
    "# Использовать ли эмбеддинги BERT вместо TF-IDF векторизации (True или False)\n",
    "USE_BERT = True\n",
    "\n",
    "# Директория с моделями hugging face (если None, то будет использована директория по умолчанию)\n",
    "HF_FOLDER = None"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55dd8989828b9744"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def find_folder(name, parent_directory):\n",
    "    folder_path = os.path.join(parent_directory, 'messages')\n",
    "\n",
    "    directory_num = 0\n",
    "    \n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for directory in dirs:\n",
    "            dir_path = os.path.join(root, directory)\n",
    "            file_path = os.path.join(dir_path, \"messages0.html\")\n",
    "            if os.path.isfile(file_path):\n",
    "                with open(file_path, 'r') as file:\n",
    "                    file_contents = file.read()\n",
    "                    soup = BeautifulSoup(file_contents, 'html.parser')\n",
    "                    divs = soup.find_all('div', class_='ui_crumb')\n",
    "                    title = divs[0].text\n",
    "                    if name in title:\n",
    "                        directory_num = directory\n",
    "                        break\n",
    "    return directory_num\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd37b67580068e31"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_messages(messages, messages_directory):\n",
    "    month_dict = {\n",
    "        'янв': 1,\n",
    "        'фев': 2,\n",
    "        'мар': 3,\n",
    "        'апр': 4,\n",
    "        'мая': 5,\n",
    "        'июн': 6,\n",
    "        'июл': 7,\n",
    "        'авг': 8,\n",
    "        'сен': 9,\n",
    "        'окт': 10,\n",
    "        'ноя': 11,\n",
    "        'дек': 12}\n",
    "    count = 0\n",
    "    for _, _, files in os.walk(messages_directory):\n",
    "        count += len(files)\n",
    "    pbar = pyprind.ProgBar(count)\n",
    "    for filename in os.listdir(messages_directory):\n",
    "        if os.path.isfile(os.path.join(messages_directory, filename)):\n",
    "            with open(os.path.join(messages_directory, filename), 'r') as file:\n",
    "                content = file.read()\n",
    "                #soup = BeautifulSoup(content, 'html.parser')\n",
    "                soup = LxmlSoup(content)\n",
    "                divs = soup.find_all('div', class_='message')\n",
    "                for div in divs:\n",
    "                    div_content = div.text()\n",
    "                    div_content = div_content.split('\\n')\n",
    "                    div_dict = {}\n",
    "                    \n",
    "                    div_dict['text'] = div_content[1]\n",
    "                    author_and_time = div_content[0].split(',')\n",
    "                    \n",
    "                    div_dict['author'] = author_and_time[0]\n",
    "                    datetime = author_and_time[1].split(' в ')\n",
    "                    div_dict['time'] = datetime[1]\n",
    "                    date = datetime[0].split(' ')\n",
    "                    div_dict['day'] = date[1]\n",
    "                    div_dict['month'] = month_dict[date[2]]\n",
    "                    div_dict['year'] = date[3]\n",
    "                    messages.loc[len(messages)] = div_dict\n",
    "                pbar.update()\n",
    "    return messages"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3a3859fbb7c62c5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "\n",
    "messages_folder = find_folder(NAME, parent_directory)\n",
    "if messages_folder == 0:\n",
    "    raise ValueError(\"Такой чат не найден\")\n",
    "path_to_messages = 'messages/'+str(messages_folder)\n",
    "print('Чат найден, id: ', messages_folder)\n",
    "messages_directory = os.path.join(parent_directory, path_to_messages)\n",
    "\n",
    "print(messages_directory)\n",
    "filename = current_directory + '/savedata/' + str(messages_folder) + '.csv'\n",
    "if os.path.exists(filename) and READ_FROM_CSV:\n",
    "    messages = pd.read_csv(filename)\n",
    "    print('Информация о чате извлечена из сохраненного файла')\n",
    "else:\n",
    "    print('Информация о чате не найдена в сохраненных файла. Начат парсинг html файлов для извлечения информации')\n",
    "    messages = pd.DataFrame(columns=['day', 'month', 'year', 'time', 'author', 'text'])\n",
    "    start_time = time()\n",
    "    messages = get_messages(messages, messages_directory)\n",
    "    end_time = time()\n",
    "    print('Время парсинга: ', end_time - start_time, ' секунд')\n",
    "    if SAVE_TO_CSV:\n",
    "        os.chdir(current_directory)\n",
    "        csv_path = 'savedata/' + str(messages_folder) + '.csv'\n",
    "        messages.to_csv(csv_path, encoding='utf-8-sig', index=False)\n",
    "        print('Информация о чате извлечена и сохранена в csv файл')\n",
    "    else:\n",
    "        print('Информация о чате извлечена. У вас установлен флаг SAVE_TO_CSV = False, поэтому информация о чате не будет сохранена в csv файл. При следующем запуске будет осуществлен повторный парсинг, что может занять продолжительное время')\n",
    "\n",
    "messages.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf239c703a11edcc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "messages.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef0c65ffba9884ce"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "messages['date'] = pd.to_datetime(messages['month'].astype(str) + '-' + messages['year'].astype(str))\n",
    "max_year = messages['year'].max()\n",
    "messages_in_year = messages[messages['year'] == max_year]\n",
    "max_month = messages_in_year['month'].max()\n",
    "\n",
    "count_by_date = messages[(messages['year'] != max_year) | (messages['month'] != max_month)].groupby('date').size()\n",
    "count_by_date.plot(kind='line')\n",
    "\n",
    "plt.xlabel('Даты')\n",
    "plt.ylabel('Количество сообщений')\n",
    "plt.title('Количество сообщений в месяц')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69a113c875de74d9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "authors = messages['author'].unique()\n",
    "for author in authors:\n",
    "    count_by_date_authors = messages[((messages['year'] != max_year) | (messages['month'] != max_month)) & (messages['author']==author)].groupby('date').size()\n",
    "    count_by_date_authors.plot(kind='line', label=author)\n",
    "\n",
    "\n",
    "plt.xlabel('Даты')\n",
    "plt.ylabel('Количество сообщений')\n",
    "plt.legend()\n",
    "plt.title('Количество сообщений в месяц (по отправителям)')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "afd2e8c5547775b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "avg_len = messages.groupby('author')['text'].apply(lambda x: x.str.len().mean())\n",
    "print(avg_len)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ff47620bce7133e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cluster = messages['text']\n",
    "df_cluster.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e75f48f0db005e9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cluster = df_cluster.fillna('None')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da18194cb21c59cb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def tokenize_row_stopwords(row):\n",
    "    stemmer = SnowballStemmer(\"russian\")\n",
    "    nltk_stopwords = stopwords.words('russian')\n",
    "    tokenizer = nltk.tokenize.word_tokenize(row, language='russian')\n",
    "    tokens = [i for i in tokenizer if (i not in string.punctuation) and (i not in nltk_stopwords)]\n",
    "    return [stemmer.stem(word) for word in tokens]\n",
    "\n",
    "def text_vectorization_stopwords(df, n_grams = (1, 2)):\n",
    "    vectorizer = TfidfVectorizer(min_df=MIN_DF, max_df=0.5, ngram_range=n_grams, tokenizer=lambda text: tokenize_row_stopwords(text))\n",
    "    features = vectorizer.fit_transform(df)\n",
    "    return pd.DataFrame(features.todense(), columns=vectorizer.get_feature_names_out()), vectorizer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7400a6a00d7db41"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class BertVectorizer:\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        if HF_FOLDER:\n",
    "            self.model = SentenceTransformer('LaBSE', cache_folder=HF_FOLDER)\n",
    "        else:\n",
    "            self.model = SentenceTransformer('LaBSE')\n",
    "            \n",
    "    def vectorize(self):\n",
    "        embeddings =  self.model.encode(self.dataset, show_progress_bar=True)\n",
    "        return pd.DataFrame(embeddings)\n",
    "        "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6a11eb30dc22acf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if USE_BERT == False:\n",
    "    df_cluster_vector, vectorizer = text_vectorization_stopwords(df_cluster, n_grams=(1, 2))\n",
    "else:\n",
    "    bert = BertVectorizer(df_cluster)\n",
    "    df_cluster_vector = bert.vectorize()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c68089a2efda7e2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pca = PCA(n_components=PCA_COMPONENTS)\n",
    "pca.fit(df_cluster_vector)\n",
    "if USE_PCA:\n",
    "    df_cluster_vector = pca.transform(df_cluster_vector)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d551f5f22cf9fcc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if MODEL_TYPE == 'DBSCAN':\n",
    "    model = DBSCAN(eps=ETA, min_samples=5)\n",
    "elif MODEL_TYPE == 'KMeans':\n",
    "    model = KMeans(n_clusters=MAX_CLUSTERS, random_state=0)\n",
    "elif MODEL_TYPE == 'Spectral':\n",
    "    model = SpectralClustering(n_clusters=MAX_CLUSTERS, random_state=0, affinity='nearest_neighbors')\n",
    "clusters = model.fit_predict(df_cluster_vector)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e45e5fc2866e9a5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_with_clusters = pd.concat([df_cluster, pd.Series(clusters, name='cluster_label')], axis=1)\n",
    "df_with_clusters.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18209ec13ee5b4e2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "unique_labels = df_with_clusters['cluster_label'].unique()\n",
    "for label in unique_labels:\n",
    "    cluster_texts = df_with_clusters[df_with_clusters['cluster_label'] == label]['text']\n",
    "    print(f\"Кластер {label}:\")\n",
    "    print(cluster_texts.head(20))\n",
    "    print(\"Количество сообщений в кластере:\", len(cluster_texts))\n",
    "    print(\"---------------------------------------------\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "468bcc29fb738131"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_pca_reduced(X, y, PCA_COMPONENTS):\n",
    "    unique_labels = y.unique()\n",
    "    colors = plt.cm.rainbow(np.linspace(0, 1, len(unique_labels)))\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    if PCA_COMPONENTS == 3:\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "    for cl, color in zip(unique_labels, colors):\n",
    "        indices = np.where(y == cl)\n",
    "        points = X[indices]\n",
    "        if PCA_COMPONENTS == 3:\n",
    "            ax.scatter(points[:, 0], points[:, 1], points[:, 2], color=color, label=cl)\n",
    "        else:\n",
    "            plt.scatter(points[:, 0], points[:, 1], color=color, label=cl)\n",
    "    if PCA_COMPONENTS == 3:\n",
    "        ax.set_xlabel('PCA Component 1')\n",
    "        ax.set_ylabel('PCA Component 2')\n",
    "        ax.set_zlabel('PCA Component 3')\n",
    "        ax.set_title('PCA Reduced Representation of X')\n",
    "    else:\n",
    "        plt.xlabel('PCA Component 1')\n",
    "        plt.ylabel('PCA Component 2')\n",
    "        plt.title('PCA Reduced Representation of X')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_pca(X, y, pca, PCA_COMPONENTS):\n",
    "    X_reduced = pca.transform(X)\n",
    "    plot_pca_reduced(X_reduced, y, PCA_COMPONENTS)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7274a14a682bc88e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if PCA_COMPONENTS == 2 or PCA_COMPONENTS == 3:\n",
    "    if USE_PCA:\n",
    "        plot_pca_reduced(df_cluster_vector[:POINT_COUNT], df_with_clusters['cluster_label'][:POINT_COUNT], PCA_COMPONENTS)\n",
    "    else:\n",
    "        plot_pca(df_cluster_vector[:POINT_COUNT], df_with_clusters['cluster_label'][:POINT_COUNT], pca, PCA_COMPONENTS)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cac9785abe1bf121"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2bab592c6f977043"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
